{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8801368a-3c8b-4934-a823-8eefd3e5d8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for necessary packages...\n",
      "'pandas' is already installed.\n",
      "'numpy' is already installed.\n",
      "'matplotlib' is already installed.\n",
      "'seaborn' is already installed.\n",
      "'torch' is already installed.\n",
      "'scikit-learn' is already installed.\n",
      "'optuna' is already installed.\n",
      "\n",
      "All required packages are already installed! ðŸŽ‰\n",
      "--------------------------------------------------\n",
      "Setup complete. You can now run the rest of your notebook.\n"
     ]
    }
   ],
   "source": [
    "# Checking Dependencies\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib.util\n",
    "\n",
    "print(\"Checking for necessary packages...\")\n",
    "\n",
    "# A dictionary of (package_name_on_pip, module_name_to_import)\n",
    "packages = {\n",
    "    'pandas': 'pandas',\n",
    "    'numpy': 'numpy',\n",
    "    'matplotlib': 'matplotlib',\n",
    "    'seaborn': 'seaborn',\n",
    "    'scikit-learn': 'sklearn',  # Note: pip name is scikit-learn, import name is sklearn\n",
    "    'optuna': 'optuna'\n",
    "}\n",
    "\n",
    "missing_packages = []\n",
    "for install_name, import_name in packages.items():\n",
    "    spec = importlib.util.find_spec(import_name)\n",
    "    if spec is None:\n",
    "        print(f\"'{install_name}' not found. Adding to installation list.\")\n",
    "        missing_packages.append(install_name)\n",
    "    else:\n",
    "        print(f\"'{install_name}' is already installed.\")\n",
    "\n",
    "if not missing_packages:\n",
    "    print(\"\\nAll required packages are already installed!\")\n",
    "else:\n",
    "    print(f\"\\nInstalling missing packages: {', '.join(missing_packages)}\")\n",
    "    try:\n",
    "        # Use sys.executable to ensure pip is called from the correct Python interpreter\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *missing_packages])\n",
    "        print(\"All missing packages installed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during installation: {e}\")\n",
    "        print(\"Please try installing the packages manually.\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"Setup complete. You can now run the rest of your notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8fcbd8-a790-4b43-b384-56a742304bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries and setting seed\n",
    "\n",
    "# Importing core libraries for data manipulation, visualization, and random operations.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import random\n",
    "import copy\n",
    "\n",
    "# Importing scikit-learn for machine learning utilities such as metrics, model selection, and preprocessing.\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import TargetEncoder, OrdinalEncoder, StandardScaler, power_transform\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Importing Optuna for hyperparameter optimization and visualization of studies.\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_parallel_coordinate, plot_param_importances\n",
    "\n",
    "# Setting up necessary seeds for reproducibility across runs.\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b751429-05ef-4680-8984-eaf60751c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from 'data.csv' into a pandas DataFrame.\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a12cba96-2b5f-478a-b740-8632276fb41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the shape of the DataFrame (number of rows, number of columns).\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cf96515-76f1-425d-a9e6-6cbc5087f92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     588 non-null    object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# inspecting data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "879195eb-f077-475e-b849-8c317fa651ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary features\n",
    "df.drop(columns='Id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5ecdb6-389e-4f9a-994e-6affe0d02bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating features (X) and target (y), and applying a log transformation to the SalePrice (y).\n",
    "X = df.iloc[:,:-1]\n",
    "y = np.log(df.iloc[:,-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1afe8d48-04f9-4f4f-9a48-15f81652bdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 79), (1460, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fe37c14-dee4-41c1-b157-4cb5ab03e43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the 'GarageYrBlt' feature by calculating 1 divided by (2025 - YearBuilt) to represent age inversely.\n",
    "X.loc[:,'GarageYrBlt'] = 1/(2025-X.GarageYrBlt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09b35ea8-85e5-4e87-b467-bad51c3ce5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training, testing, and development sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=seed)\n",
    "X_test, X_dev, y_test, y_dev = train_test_split(X_test,y_test,test_size=0.5,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cc281d5-a1cd-4f27-9c58-aa6024ed8e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(876, 292, 292)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the number of samples in the training, testing, and development sets.\n",
    "X_train.shape[0],X_test.shape[0],X_dev.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c010896c-0a44-4be8-9877-8dcb9202eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_imp = ['CentralAir'] # Features to be imputed with a constant 'N' (binary)\n",
    "mode_imp = ['Electrical'] # Features to be imputed with the most frequent value\n",
    "# Features to be imputed with a constant 'NA' (object type columns, excluding mode_imp and binary_imp)\n",
    "na_imp = X_train.select_dtypes('object').columns.drop([*mode_imp,*binary_imp])\n",
    "zero_imp = X_train.select_dtypes('number').columns # Numerical features to be imputed with 0\n",
    "\n",
    "# Defining a ColumnTransformer for imputation strategies based on feature types.\n",
    "impute = ColumnTransformer([\n",
    "    ('na_imp',SimpleImputer(strategy='constant',fill_value='NA'), na_imp),\n",
    "    ('zero_imp',SimpleImputer(strategy='constant',fill_value=0), zero_imp),\n",
    "    ('mode_imp',SimpleImputer(strategy='most_frequent'), mode_imp),\n",
    "    ('binary_imp',SimpleImputer(strategy='constant',fill_value='N'),binary_imp)\n",
    "    ], remainder='passthrough', verbose_feature_names_out=False).set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d028172-be80-4f96-8a65-ed6589ddd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining lists of features based on their type and encoding strategy.\n",
    "ord_feat = ['LotShape','Utilities','LandSlope','BldgType','ExterQual','ExterCond',\n",
    "            'BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "            'HeatingQC','Electrical','KitchenQual','FireplaceQu','GarageFinish',\n",
    "            'GarageQual','GarageCond','PavedDrive','PoolQC','Fence'] # Ordinal features\n",
    "num_feat = X_train.select_dtypes('number').columns # Numerical features\n",
    "bi_feat=['CentralAir'] # Binary features\n",
    "# Categorical features (excluding ordinal, numerical, and binary)\n",
    "cat_feat = X_train.columns.drop([*ord_feat,*num_feat,*bi_feat])\n",
    "\n",
    "# Dictionary defining the order of categories for ordinal encoding.\n",
    "ord_dic = dict(\n",
    "    LotShape = ['NA','Reg', 'IR1', 'IR2', 'IR3'],\n",
    "    Utilities =['NA','AllPub', 'NoSeWr','NoSeWa','ELO'],\n",
    "    LandSlope =['NA','Gtl', 'Mod', 'Sev'],\n",
    "    BldgType =['NA','1Fam', '2fmCon', 'Duplex', 'TwnhsE', 'Twnhs'],\n",
    "    BsmtExposure = ['NA','No', 'Gd','Av','Mn'],\n",
    "    BsmtFinType1 = ['NA','GLQ', 'ALQ', 'BLQ',  'Rec', 'LwQ','Unf',],\n",
    "    BsmtFinType2 = ['NA','GLQ', 'ALQ', 'BLQ',  'Rec', 'LwQ','Unf',],\n",
    "    GarageFinish = ['NA','Fin','RFn','Unf'],\n",
    "    PavedDrive = ['NA','Y', 'N', 'P'],\n",
    "    Fence = ['NA','MnPrv', 'GdWo', 'GdPrv', 'MnWw'],\n",
    "    Electrical = ['NA','SBrkr','FuseA','FuseF','FuseP','Mix'],\n",
    "    rest =['NA','Ex','Gd','TA', 'Fa','Po'] # Default order for other ordinal features\n",
    ")\n",
    "\n",
    "# Creating a list of category orders for the OrdinalEncoder based on ord_dic.\n",
    "categories = [ord_dic[col] if col in ord_dic.keys() else ord_dic['rest'] for col in ord_feat]\n",
    "\n",
    "# Defining a ColumnTransformer for encoding different types of features.\n",
    "encode = ColumnTransformer([\n",
    "    ('oe', OrdinalEncoder(categories = categories,handle_unknown='use_encoded_value',unknown_value=-1),ord_feat), # Ordinal encoding\n",
    "    ('te', TargetEncoder(cv=10,shuffle=True,random_state=seed),cat_feat), # Target encoding for other categorical features\n",
    "    ('oe_bi', OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1),bi_feat) # Ordinal encoding for binary features\n",
    "],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7abf06a-b766-489e-8bc1-147ae5b8f9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krazz\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing pipeline\n",
    "preprocess = Pipeline([\n",
    "    ('impute',impute),\n",
    "    ('encoded',encode),\n",
    "    ('scaling',StandardScaler().set_output(transform='pandas'))\n",
    "]).set_output(transform='pandas')\n",
    "\n",
    "# Applying the preprocessing pipeline to the training, development, and test datasets.\n",
    "X_train = preprocess.fit_transform(X_train,y_train)\n",
    "X_dev = preprocess.transform(X_dev)\n",
    "X_test = preprocess.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "796b69e9-1114-4c69-9207-046644b5826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export training, and test dataset to csv\n",
    "X_train.to_csv('X_train.csv',index=False)\n",
    "y_train.to_csv('y_train.csv',index=False)\n",
    "\n",
    "X_dev.to_csv('X_dev.csv',index=False)\n",
    "y_dev.to_csv('y_dev.csv',index=False)\n",
    "\n",
    "X_test.to_csv('X_test.csv',index=False)\n",
    "y_test.to_csv('y_test.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
